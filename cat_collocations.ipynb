{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat_collocations.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvQFl0Lb49hB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VznC-an5e5n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Nk2Yc504Vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pycodestyle flake8 pycodestyle_magic\n",
        "%load_ext pycodestyle_magic\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KK4Zdbbz-nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install natasha\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2QqLgJR7zKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install joblib\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StMZX2azxXHl",
        "colab_type": "text"
      },
      "source": [
        "Задача: научиться находить в тексте лексически/стилистически неправильные сочетания (коллокации) и предлагать более правильные замены. </br>\n",
        "Алгоритм является улучшенной версией этого алгоритма https://github.com/annadmitrieva/NLP-stuff/blob/master/collocation_generation-Copy4.ipynb "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC5oMw4Dw6NZ",
        "colab_type": "text"
      },
      "source": [
        "#Этапы работы\n",
        "\n",
        "*   Автоматическое обнаружение \"неправильных\" коллокаций в тексте.\n",
        "*   Поиск замен."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DEhQpYgQcXj",
        "colab_type": "text"
      },
      "source": [
        "Скачиваем word2vec модель из rusvectores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwd70RgHSlbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://rusvectores.org/static/models/rusvectores4/ruwikiruscorpora/ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgD2XXsOQhSy",
        "colab_type": "text"
      },
      "source": [
        "Для определения домена текста используем предобученную на шестиграммах из каждого домена (по 100000 на домен) SVM. F1-score модели – 0.94. </br>\n",
        "Код модели: https://github.com/annadmitrieva/NLP-stuff/blob/master/domain_model.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av2Q34pcTLa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.dropbox.com/s/lyfk0ur0pqvcgqv/domain_model.pkl?dl=0 -O domain_model.pkl\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxSRwGTUWp6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.dropbox.com/s/y35dm5chuv54psg/suggestions.zip?dl=0 -O suggestions.zip\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aisa0dw-W1Yt",
        "colab_type": "code",
        "outputId": "c29d7ada-0bf7-4fc6-9e0e-2dc1702118de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "!unzip suggestions.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  suggestions.zip\n",
            "  inflating: suggestions_law.csv     \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._suggestions_law.csv  \n",
            "  inflating: suggestions_ling.csv    \n",
            "  inflating: __MACOSX/._suggestions_ling.csv  \n",
            "  inflating: suggestions_pol.csv     \n",
            "  inflating: __MACOSX/._suggestions_pol.csv  \n",
            "  inflating: suggestions_hist.csv    \n",
            "  inflating: __MACOSX/._suggestions_hist.csv  \n",
            "  inflating: suggestions_psy.csv     \n",
            "  inflating: __MACOSX/._suggestions_psy.csv  \n",
            "  inflating: suggestions_soc.csv     \n",
            "  inflating: __MACOSX/._suggestions_soc.csv  \n",
            "  inflating: suggestions_ec.csv      \n",
            "  inflating: __MACOSX/._suggestions_ec.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KeVWEZsTXLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import gensim\n",
        "import joblib\n",
        "from gensim.models import Word2Vec\n",
        "from natasha import NamesExtractor, AddressExtractor, DatesExtractor\n",
        "\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
        "    'ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz', binary=False)\n",
        "domain_model = joblib.load('domain_model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig3R2wvUpuMv",
        "colab_type": "code",
        "outputId": "a3b79d3b-50d7-4ead-e335-53d25c50a21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger_ru')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phW6KHcuXcQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def domain(string):\n",
        "    domain = domain_model.predict(list(string))[0]\n",
        "    df = pd.read_csv(f'suggestions_{domain}.csv')\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET70OxkDcjI5",
        "colab_type": "text"
      },
      "source": [
        "#Поиск неправильных сочетаний\n",
        "В предыдущей версии этого алгоритма (https://github.com/annadmitrieva/NLP-stuff/blob/master/collocation_generation-Copy4.ipynb) в список плохих коллокаций попадали все встретившиеся в тексте биграммы из существительных или глаголов, которых не было в эталонном списке. В результате отлавливалось много пар слов, вообще не являющихся словосочетаниями (пример – \"работы разрешение\"). Решение: добавить синтаксический парсер."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4hhc4q_VnoM",
        "colab_type": "text"
      },
      "source": [
        "##Подход 1: парсер зависимостей\n",
        "Плохими коллокациями считаются такие пары \"вершина-зависимое\", которые состоят из существительных и глаголов и которых нет в эталонных списках правильных словосочетаний (для каждого домена текста – свой список).</br>\n",
        "Для POS-тэггинга использовался метод pos_tag из NLTK для русского языка.</br>\n",
        "Для синтаксического парсинга использовался MaltParser из NLTK с предобученной моделью для русского языка. </br>\n",
        "Источник модели: http://corpus.leeds.ac.uk/mocky/ </br>\n",
        "Эталонные списки коллокаций: https://drive.google.com/drive/folders/1k_N-DZ-nLL5ro66-LxIaE4-dRwirdwZh </br>\n",
        "Код, которых использовался при сборе эталонных списков: https://github.com/MariaFjodorowa/catandthekittens/tree/develop/collocations/collocation_frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxqmEIAea2CU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://corpus.leeds.ac.uk/tools/russian.mco\n",
        "!wget http://maltparser.org/dist/maltparser-1.8.1.zip\n",
        "!unzip maltparser-1.8.1.zip\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsBBabRMhKnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export MALT_PARSER=$HOME/maltparser-1.8.1/\n",
        "!export MALT_MODEL=$HOME/russian.mco"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6oPPziptvmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pos_tag_rus(tokens):\n",
        "    return nltk.pos_tag(tokens, lang='rus')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGk1vb92ipvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "syntax_parser = nltk.parse.malt.MaltParser(\n",
        "    'maltparser-1.8.1', 'russian.mco', tagger=pos_tag_rus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6x_yisGUKzt",
        "colab_type": "text"
      },
      "source": [
        "Несколько плохих текстов, на которых будем проверять, насколько хорошо находятся плохие коллокации. Источник – примеры плохой лексической сочетаемости из домашнего задания по академическому письму 1 курса ОП \"Фундаментальная и прикладная лингвистика\" НИУ ВШЭ 2017 года."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wTiBajJlZ3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad_text_pol = \"\"\"В то же время, Путин умолчал от египетского населения данные о том, \n",
        "насколько милитаризируется сама Россия и насколько выросли ее военные расходы. \n",
        "Обама улетел из Вашингтона на вертолете, а Байден - на поезде.\"\"\"\n",
        "bad_text_hist = \"\"\"Маккензи ограничивается рамками исследования 1928 – 1943, исследуя преимущественно идеологию Коминтерна сталинской эпохи, \n",
        "перечисляет причины на то, чтобы рассматривать 1928 год как переломный. \n",
        "Александр Шубин посвящает свою книгу большей частью на исследование общественно-политических движений в послесталинский СССР, \n",
        "1953 – 85 годов. В строках читаются напряжение и недоверие власти.\"\"\"\n",
        "bad_text_ling = \"\"\"Следует избегать наводящие вопросы. Тем не менее существовало несколько точек зрения о создании алфавита. \n",
        "Предлагая ту или иную гипотезу, нельзя основываться и ссылаться только на результаты своего собственного исследования. \n",
        "Необходимо внимательное изучение опыта других ученых. \n",
        "Термин морфология обычно соотносится к части грамматики языка. Однако этот термин в истории науки употреблялся и в совсем ином значении.\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm1TcbjMrnJM",
        "colab_type": "code",
        "outputId": "04c99e8d-5de6-49e1-92c8-8d5b5edfdc9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# проверим, правильно ли работает парсер\n",
        "sents = nltk.sent_tokenize(bad_text_pol)\n",
        "nodes = syntax_parser.parse_one(sents[0].split()).nodes\n",
        "for node in nodes.keys():\n",
        "    head = nodes[node]['head']\n",
        "    if head is not None and nodes[head]['word'] is not None:\n",
        "        print(f\"Head: {nodes[head]['word']} {nodes[head]['ctag']}. \" +\n",
        "              f\"Dependent: {nodes[node]['word']} {nodes[node]['ctag']}.\")\n",
        "# достаточно хорошо – большая часть пар вершина-зависимое выделены корректно"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Head: то A-PRO=n. Dependent: В PR.\n",
            "Head: то A-PRO=n. Dependent: же PART.\n",
            "Head: то A-PRO=n. Dependent: время, S.\n",
            "Head: время, S. Dependent: Путин S.\n",
            "Head: от PR. Dependent: умолчал V.\n",
            "Head: Путин S. Dependent: от PR.\n",
            "Head: населения S. Dependent: египетского A=n.\n",
            "Head: то A-PRO=n. Dependent: населения S.\n",
            "Head: населения S. Dependent: данные S.\n",
            "Head: том, S. Dependent: насколько ADV.\n",
            "Head: сама A-PRO=f. Dependent: милитаризируется V.\n",
            "Head: насколько ADV. Dependent: и CONJ.\n",
            "Head: выросли V. Dependent: насколько ADV.\n",
            "Head: выросли V. Dependent: ее S.\n",
            "Head: ее S. Dependent: военные A=pl.\n",
            "Head: военные A=pl. Dependent: расходы. S.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OCtnuWCoFQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search(text, collocations):\n",
        "    \"\"\"text – строка, collocations – датафрейм pandas.\n",
        "    Возвращается словарь candidates,\n",
        "    где ключи – пары слов, а значения – пары тэгов\"\"\"\n",
        "    candidates = {}\n",
        "    first = list(collocations.first_word)\n",
        "    second = list(collocations.second_word)\n",
        "    clean_text = re.sub(\"\\([a-zA-z\\d .,:]*\\)|[a-zA-z\\d]*\", \"\", text)\n",
        "    # чистим текст от библиографических ссылок\n",
        "    # и токенов, состоящих только из латиницы и цифр\n",
        "    extractors = [NamesExtractor(), AddressExtractor(), DatesExtractor()]\n",
        "    named_entities = []\n",
        "    # составляем список всех именованных сущностей, встречающихся в тексте\n",
        "    for extractor in extractors:\n",
        "        matches = extractor(text)\n",
        "        for match in matches:\n",
        "            start, stop = match.span\n",
        "            for i in re.findall('\\w+', text[start: stop]):\n",
        "                named_entities.append(i.lower())\n",
        "    # разбиваем текст на предложения, а предложения на слова\n",
        "    sents = nltk.sent_tokenize(text)\n",
        "    for i in range(len(sents)):\n",
        "        nodes = syntax_parser.parse_one(sents[i].split()).nodes\n",
        "        for node in nodes.keys():\n",
        "            head = nodes[node]['head']\n",
        "            if head is not None and nodes[head]['word'] is not None \\\n",
        "                    and nodes[head]['word'].lower() not in named_entities \\\n",
        "                    and nodes[node]['word'].lower() not in named_entities \\\n",
        "                    and nodes[head]['ctag'] in ['S', 'V'] \\\n",
        "                    and nodes[node]['ctag'] in ['S', 'V']:\n",
        "                word_1 = nodes[head]['word'].lower()\n",
        "                word_2 = nodes[node]['word'].lower()\n",
        "                tag_1 = nodes[head]['ctag']\n",
        "                tag_2 = nodes[node]['ctag']\n",
        "                if word_1 in first or word_2 in second:\n",
        "                    if word_1 in first and word_2 in second:\n",
        "                        indices_1 = [i for i, x in enumerate(first)\n",
        "                                     if x == word_1]\n",
        "                        indices_2 = [i for i, x in enumerate(second)\n",
        "                                     if x == word_2]\n",
        "                        if not set(indices_1).isdisjoint(indices_2):\n",
        "                            pass\n",
        "                        else:\n",
        "                            candidates[(word_1, word_2)] = (tag_1, tag_2)\n",
        "                    else:\n",
        "                        candidates[(word_1, word_2)] = (tag_1, tag_2)\n",
        "    return candidates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSOOGGUAGLJW",
        "colab_type": "text"
      },
      "source": [
        "Проверим, как функция search работает на наших плохих текстах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkYt7PDLirB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d56f29de-fb1a-4167-9b43-b2cbb28b5b48"
      },
      "source": [
        "candidates_pol = search(bad_text_pol, pd.read_csv('suggestions_pol.csv'))\n",
        "candidates_pol"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('населения', 'данные'): ('S', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hszw_bq9IkNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2ac17862-0b64-463b-94b3-03441091a182"
      },
      "source": [
        "candidates_hist = search(bad_text_hist, pd.read_csv('suggestions_hist.csv'))\n",
        "candidates_hist"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('недоверие', 'власти.'): ('S', 'S'),\n",
              " ('ограничивается', 'рамками'): ('V', 'S'),\n",
              " ('перечисляет', 'причины'): ('V', 'S'),\n",
              " ('рамками', 'исследования'): ('S', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrMh9eD3Q3Sd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bd60e0f6-dd24-4ea8-903a-d0bd9e250eae"
      },
      "source": [
        "candidates_ling = search(bad_text_ling, pd.read_csv('suggestions_ling.csv'))\n",
        "candidates_ling"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('зрения', 'создании'): ('S', 'S'),\n",
              " ('изучение', 'опыта'): ('S', 'S'),\n",
              " ('наводящие', 'избегать'): ('V', 'V'),\n",
              " ('наводящие', 'следует'): ('V', 'V'),\n",
              " ('создании', 'алфавита.'): ('S', 'S'),\n",
              " ('термин', 'морфология'): ('S', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LC0cSKfdCWY",
        "colab_type": "text"
      },
      "source": [
        "Результаты не очень хорошие – выделенные пары либо вообще не являются словосочетаниями (\"населения данные\", \"зрения создании\"), либо являются правильными словосочетаниями (\"недоверие власти\", \"термин морфология\"), при этом ни одно из спорных словосочетаний (\"умолчал данные\", \"избегать вопросы\") не выделены."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bClRA49ASBko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
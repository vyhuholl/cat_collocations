{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat_collocations.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvQFl0Lb49hB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VznC-an5e5n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Nk2Yc504Vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pycodestyle flake8 pycodestyle_magic\n",
        "%load_ext pycodestyle_magic\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KK4Zdbbz-nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install natasha\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2QqLgJR7zKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install joblib\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StMZX2azxXHl",
        "colab_type": "text"
      },
      "source": [
        "Задача: научиться находить в тексте лексически/стилистически неправильные сочетания (коллокации) и предлагать более правильные замены. <br>\n",
        "Алгоритм является улучшенной версией этого алгоритма https://github.com/annadmitrieva/NLP-stuff/blob/master/collocation_generation-Copy4.ipynb "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC5oMw4Dw6NZ",
        "colab_type": "text"
      },
      "source": [
        "#Этапы работы\n",
        "\n",
        "*   Автоматическое обнаружение \"неправильных\" коллокаций в тексте.\n",
        "*   Поиск замен."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DEhQpYgQcXj",
        "colab_type": "text"
      },
      "source": [
        "Скачиваем word2vec модель из rusvectores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwd70RgHSlbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://rusvectores.org/static/models/rusvectores4/ruwikiruscorpora/ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgD2XXsOQhSy",
        "colab_type": "text"
      },
      "source": [
        "Для определения домена текста используем предобученную на шестиграммах из каждого домена (по 100000 на домен) SVM. F1-score модели – 0.94. <br>\n",
        "Код модели: https://github.com/annadmitrieva/NLP-stuff/blob/master/domain_model.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av2Q34pcTLa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.dropbox.com/s/lyfk0ur0pqvcgqv/domain_model.pkl?dl=0 -O domain_model.pkl\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxSRwGTUWp6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.dropbox.com/s/y35dm5chuv54psg/suggestions.zip?dl=0 -O suggestions.zip\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aisa0dw-W1Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip suggestions.zip\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KeVWEZsTXLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import gensim\n",
        "import joblib\n",
        "import pickle\n",
        "from gensim.models import Word2Vec\n",
        "from natasha import NamesExtractor, AddressExtractor, DatesExtractor\n",
        "\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
        "    'ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz', binary=False)\n",
        "domain_model = joblib.load('domain_model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig3R2wvUpuMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger_ru')\n",
        "nltk.download('punkt')\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phW6KHcuXcQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def domain(string):\n",
        "    domain = domain_model.predict(list(string))[0]\n",
        "    df = pd.read_csv(f'suggestions_{domain}.csv')\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET70OxkDcjI5",
        "colab_type": "text"
      },
      "source": [
        "#Поиск неправильных сочетаний\n",
        "В предыдущей версии этого алгоритма (https://github.com/annadmitrieva/NLP-stuff/blob/master/collocation_generation-Copy4.ipynb) в список плохих коллокаций попадали все встретившиеся в тексте биграммы из существительных или глаголов, которых не было в эталонном списке. В результате отлавливалось много пар слов, вообще не являющихся словосочетаниями (пример – \"работы разрешение\"). Решение: добавить синтаксический парсер. <br>\n",
        "Будем считать плохими коллокациями такие пары \"вершина-зависимое\", которые состоят из существительных и глаголов и которых нет в эталонных списках правильных словосочетаний (для каждого домена текста – свой список).<br>\n",
        "Эталонные списки коллокаций: https://drive.google.com/drive/folders/1k_N-DZ-nLL5ro66-LxIaE4-dRwirdwZh <br>\n",
        "Код, который использовался при сборе эталонных списков: https://github.com/MariaFjodorowa/catandthekittens/tree/develop/collocations/collocation_frequencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6x_yisGUKzt",
        "colab_type": "text"
      },
      "source": [
        "Несколько плохих текстов, на которых будем проверять, насколько хорошо находятся плохие коллокации. Источник – примеры плохой лексической сочетаемости из домашнего задания по академическому письму 1 курса ОП \"Фундаментальная и прикладная лингвистика\" НИУ ВШЭ 2017 года."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wTiBajJlZ3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad_text_pol = \"\"\"В то же время, Путин умолчал от египетского населения данные о том, \n",
        "насколько милитаризируется сама Россия и насколько выросли ее военные расходы. \n",
        "Обама улетел из Вашингтона на вертолете, а Байден - на поезде.\"\"\"\n",
        "bad_text_hist = \"\"\"Маккензи ограничивается рамками исследования 1928 – 1943, исследуя преимущественно идеологию Коминтерна сталинской эпохи, \n",
        "перечисляет причины на то, чтобы рассматривать 1928 год как переломный. \n",
        "Александр Шубин посвящает свою книгу большей частью на исследование общественно-политических движений в послесталинский СССР, \n",
        "1953 – 85 годов. В строках читаются напряжение и недоверие власти.\"\"\"\n",
        "bad_text_ling = \"\"\"Следует избегать наводящие вопросы. Тем не менее существовало несколько точек зрения о создании алфавита. \n",
        "Предлагая ту или иную гипотезу, нельзя основываться и ссылаться только на результаты своего собственного исследования. \n",
        "Необходимо внимательное изучение опыта других ученых. \n",
        "Термин морфология обычно соотносится к части грамматики языка. Однако этот термин в истории науки употреблялся и в совсем ином значении.\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4hhc4q_VnoM",
        "colab_type": "text"
      },
      "source": [
        "##Подход 1: MaltParser (медленный и плохо работающий)\n",
        "Для POS-тэггинга использовался метод pos_tag из NLTK для русского языка.<br>\n",
        "Для синтаксического парсинга использовался MaltParser из NLTK с предобученной моделью для русского языка. <br>\n",
        "Источник модели: http://corpus.leeds.ac.uk/mocky/ <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxqmEIAea2CU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://corpus.leeds.ac.uk/tools/russian.mco\n",
        "!wget http://maltparser.org/dist/maltparser-1.8.1.zip\n",
        "!unzip maltparser-1.8.1.zip\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsBBabRMhKnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export MALT_PARSER=$HOME/maltparser-1.8.1/\n",
        "!export MALT_MODEL=$HOME/russian.mco"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6oPPziptvmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pos_tag_rus(tokens):\n",
        "    return nltk.pos_tag(tokens, lang='rus')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGk1vb92ipvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "syntax_parser = nltk.parse.malt.MaltParser(\n",
        "    'maltparser-1.8.1', 'russian.mco', tagger=pos_tag_rus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm1TcbjMrnJM",
        "colab_type": "code",
        "outputId": "3f6622a2-0588-464c-9537-73b5d2f28ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# проверим, правильно ли работает парсер\n",
        "sents = nltk.sent_tokenize(bad_text_pol)\n",
        "nodes = syntax_parser.parse_one(sents[0].split()).nodes\n",
        "for node in nodes.keys():\n",
        "    head = nodes[node]['head']\n",
        "    if head is not None and nodes[head]['word'] is not None:\n",
        "        print(f\"Head: {nodes[head]['word']} {nodes[head]['ctag']}. \" +\n",
        "              f\"Dependent: {nodes[node]['word']} {nodes[node]['ctag']}.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Head: то A-PRO=n. Dependent: В PR.\n",
            "Head: то A-PRO=n. Dependent: же PART.\n",
            "Head: то A-PRO=n. Dependent: время, S.\n",
            "Head: время, S. Dependent: Путин S.\n",
            "Head: от PR. Dependent: умолчал V.\n",
            "Head: Путин S. Dependent: от PR.\n",
            "Head: населения S. Dependent: египетского A=n.\n",
            "Head: то A-PRO=n. Dependent: населения S.\n",
            "Head: населения S. Dependent: данные S.\n",
            "Head: том, S. Dependent: насколько ADV.\n",
            "Head: сама A-PRO=f. Dependent: милитаризируется V.\n",
            "Head: насколько ADV. Dependent: и CONJ.\n",
            "Head: выросли V. Dependent: насколько ADV.\n",
            "Head: выросли V. Dependent: ее S.\n",
            "Head: ее S. Dependent: военные A=pl.\n",
            "Head: военные A=pl. Dependent: расходы. S.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OCtnuWCoFQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search(text, collocations):\n",
        "    \"\"\"text – строка, collocations – датафрейм pandas.\n",
        "    Возвращается словарь candidates,\n",
        "    где ключи – пары слов, а значения – пары тэгов\"\"\"\n",
        "    candidates = {}\n",
        "    first = list(collocations.first_word)\n",
        "    second = list(collocations.second_word)\n",
        "    clean_text = re.sub(\"\\([a-zA-z\\d .,:]*\\)|[a-zA-z\\d]*\", \"\", text)\n",
        "    # чистим текст от библиографических ссылок\n",
        "    # и токенов, состоящих только из латиницы и цифр\n",
        "    extractors = [NamesExtractor(), AddressExtractor(), DatesExtractor()]\n",
        "    named_entities = []\n",
        "    # составляем список всех именованных сущностей, встречающихся в тексте\n",
        "    for extractor in extractors:\n",
        "        matches = extractor(text)\n",
        "        for match in matches:\n",
        "            start, stop = match.span\n",
        "            for i in re.findall('\\w+', text[start: stop]):\n",
        "                named_entities.append(i.lower())\n",
        "    # разбиваем текст на предложения, а предложения на слова\n",
        "    sents = nltk.sent_tokenize(text)\n",
        "    for i in range(len(sents)):\n",
        "        nodes = syntax_parser.parse_one(sents[i].split()).nodes\n",
        "        for node in nodes.keys():\n",
        "            head = nodes[node]['head']\n",
        "            if head is not None and nodes[head]['word'] is not None \\\n",
        "                    and nodes[head]['word'].lower() not in named_entities \\\n",
        "                    and nodes[node]['word'].lower() not in named_entities \\\n",
        "                    and nodes[head]['ctag'] in ['S', 'V'] \\\n",
        "                    and nodes[node]['ctag'] in ['S', 'V']:\n",
        "                word_1 = nodes[head]['word'].lower()\n",
        "                word_2 = nodes[node]['word'].lower()\n",
        "                tag_1 = nodes[head]['ctag']\n",
        "                tag_2 = nodes[node]['ctag']\n",
        "                if word_1 in first or word_2 in second:\n",
        "                    if word_1 in first and word_2 in second:\n",
        "                        indices_1 = [i for i, x in enumerate(first)\n",
        "                                     if x == word_1]\n",
        "                        indices_2 = [i for i, x in enumerate(second)\n",
        "                                     if x == word_2]\n",
        "                        if not set(indices_1).isdisjoint(indices_2):\n",
        "                            pass\n",
        "                        else:\n",
        "                            candidates[(word_1, word_2)] = (tag_1, tag_2)\n",
        "                    else:\n",
        "                        candidates[(word_1, word_2)] = (tag_1, tag_2)\n",
        "    return candidates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSOOGGUAGLJW",
        "colab_type": "text"
      },
      "source": [
        "Проверим, как функция search работает на наших плохих текстах."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkYt7PDLirB7",
        "colab_type": "code",
        "outputId": "1487f4ca-9b6e-48a1-aa4f-c0d6bb51be05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "candidates_pol = search(bad_text_pol, pd.read_csv('suggestions_pol.csv'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 467 ms, sys: 62 ms, total: 529 ms\n",
            "Wall time: 10.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTHI2zhleizt",
        "colab_type": "code",
        "outputId": "3b05942f-f077-4a5e-d760-b5b1fd225951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "candidates_pol"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('населения', 'данные'): ('S', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hszw_bq9IkNI",
        "colab_type": "code",
        "outputId": "45a09124-00e8-4dfa-9867-e7acda0076b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "candidates_hist = search(bad_text_hist, pd.read_csv('suggestions_hist.csv'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 252 ms, sys: 66 ms, total: 318 ms\n",
            "Wall time: 16.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAkiH5vie1vW",
        "colab_type": "code",
        "outputId": "4e1edcaf-874a-41e3-d059-3bb6561e5dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "candidates_hist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('недоверие', 'власти.'): ('S', 'S'),\n",
              " ('ограничивается', 'рамками'): ('V', 'S'),\n",
              " ('перечисляет', 'причины'): ('V', 'S'),\n",
              " ('рамками', 'исследования'): ('S', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrMh9eD3Q3Sd",
        "colab_type": "code",
        "outputId": "b7dc81e3-161f-4c53-a033-7523be2ab1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "candidates_ling = search(bad_text_ling, pd.read_csv('suggestions_ling.csv'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 448 ms, sys: 142 ms, total: 590 ms\n",
            "Wall time: 31.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyq3yLYLfEL2",
        "colab_type": "code",
        "outputId": "475e2529-38d2-4452-fefa-41e6f2665918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "candidates_ling"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('зрения', 'создании'): ('S', 'S'),\n",
              " ('изучение', 'опыта'): ('S', 'S'),\n",
              " ('наводящие', 'избегать'): ('V', 'V'),\n",
              " ('наводящие', 'следует'): ('V', 'V'),\n",
              " ('создании', 'алфавита.'): ('S', 'S'),\n",
              " ('термин', 'морфология'): ('S', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LC0cSKfdCWY",
        "colab_type": "text"
      },
      "source": [
        "Результаты не очень хорошие – выделенные пары либо вообще не являются словосочетаниями (\"населения данные\", \"зрения создании\"), либо являются правильными словосочетаниями (\"недоверие власти\", \"термин морфология\"), при этом ни одно из спорных словосочетаний (\"умолчал данные\", \"избегать вопросы\") не выделены. Во многом эти ошибки вызваны плохой работой синтаксического парсера. <br>\n",
        "Кроме того, MaltParser довольно медленный."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_f_826CfR5r",
        "colab_type": "text"
      },
      "source": [
        "## Подход 2: StanfordNLP\n",
        "Попробуем другой парсер зависимостей. <br>\n",
        "Источник: https://github.com/stanfordnlp/stanfordnlp. <br>\n",
        "Зависимостный парсер в StanfordNLP работает лучше и быстрее (см. код ниже) MaltParser, кроме того, в него уже встроен морфологический тэггер с тэгом PROPN, поэтому не нужно искать какой-то ещё тэггер или дополнительно убирать именованные сущности."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saMIUP_hx2A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install stanfordnlp\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwP6VUkH2lV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import stanfordnlp\n",
        "stanfordnlp.download('ru')\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzVuVRMrVSKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = stanfordnlp.Pipeline(lang='ru', models_dir='/root/stanfordnlp_resources')\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIpgV_bohqU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(bad_text_pol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNl3hxPYV4km",
        "colab_type": "code",
        "outputId": "af90c89f-06f5-4152-fd95-e553172a6e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# посмотрим, как работает этот парсер\n",
        "doc.sentences[0].dependencies[0: 3]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(<Word index=4;text=время;lemma=время;upos=NOUN;xpos=_;feats=Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing;governor=7;dependency_relation=parataxis>,\n",
              "  'case',\n",
              "  <Word index=1;text=В;lemma=в;upos=ADP;xpos=_;feats=_;governor=4;dependency_relation=case>),\n",
              " (<Word index=4;text=время;lemma=время;upos=NOUN;xpos=_;feats=Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing;governor=7;dependency_relation=parataxis>,\n",
              "  'det',\n",
              "  <Word index=2;text=то;lemma=тот;upos=DET;xpos=_;feats=Case=Acc|Gender=Neut|Number=Sing;governor=4;dependency_relation=det>),\n",
              " (<Word index=2;text=то;lemma=тот;upos=DET;xpos=_;feats=Case=Acc|Gender=Neut|Number=Sing;governor=4;dependency_relation=det>,\n",
              "  'discourse',\n",
              "  <Word index=3;text=же;lemma=же;upos=PART;xpos=_;feats=_;governor=2;dependency_relation=discourse>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMNVobbhrTtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Так как в наших списках коллокаций используется немного другой набор тэгов,\n",
        "# лучше сразу заменять NOUN на S, а VERB на V\n",
        "tags = {'NOUN': 'S', 'VERB': 'V'}\n",
        "\n",
        "def search(text, collocations):\n",
        "    \"\"\"text – строка, collocations – датафрейм pandas.\n",
        "    Возвращается словарь candidates,\n",
        "    где ключи – пары слов, а значения – пары тэгов\"\"\"\n",
        "    candidates = {}\n",
        "    first = list(collocations.first_word)\n",
        "    second = list(collocations.second_word)\n",
        "    clean_text = re.sub(\"\\([a-zA-z\\d .,:]*\\)|[a-zA-z\\d]*\", \"\", text)\n",
        "    # чистим текст от библиографических ссылок\n",
        "    # и токенов, состоящих только из латиницы и цифр\n",
        "    parsed_text = nlp(clean_text)\n",
        "    for sent in parsed_text.sentences:\n",
        "        for dep in sent.dependencies:\n",
        "            if dep[0].upos in tags \\\n",
        "                    and dep[2].upos in tags:\n",
        "                word_1 = dep[0].text.lower()\n",
        "                word_2 = dep[2].text.lower()\n",
        "                tag_1 = tags[dep[0].upos]\n",
        "                tag_2 = tags[dep[2].upos]\n",
        "                if word_1 in first or word_2 in second:\n",
        "                    if word_1 in first and word_2 in second:\n",
        "                        indices_1 = [i for i, x in enumerate(first)\n",
        "                                     if x == word_1]\n",
        "                        indices_2 = [i for i, x in enumerate(second)\n",
        "                                     if x == word_2]\n",
        "                        if not set(indices_1).isdisjoint(indices_2):\n",
        "                            pass\n",
        "                        else:\n",
        "                            candidates[(word_1, word_2)] = (tag_1, tag_2)\n",
        "                    else:\n",
        "                        candidates[(word_1, word_2)] = (tag_1, tag_2)\n",
        "    return candidates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aRtbx6NZ1g7",
        "colab_type": "code",
        "outputId": "e0cc24e6-1a7a-4cdb-c153-2f5224f9fb7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "candidates_pol = search(bad_text_pol, pd.read_csv('suggestions_pol.csv'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 174 ms, sys: 17.1 ms, total: 191 ms\n",
            "Wall time: 199 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFMvNFfDfkgp",
        "colab_type": "code",
        "outputId": "965298ea-ab49-4ac2-cb48-758ccb006f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "candidates_pol"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('выросли', 'расходы'): ('V', 'S'),\n",
              " ('умолчал', 'время'): ('V', 'S'),\n",
              " ('умолчал', 'данные'): ('V', 'S'),\n",
              " ('умолчал', 'населения'): ('V', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAKP6hxBaHpI",
        "colab_type": "code",
        "outputId": "af9ec3d8-58dc-4a43-9867-099d3bb680d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "candidates_hist = search(bad_text_hist, pd.read_csv('suggestions_hist.csv'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 223 ms, sys: 12 ms, total: 235 ms\n",
            "Wall time: 242 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPr4vO9UfqAR",
        "colab_type": "code",
        "outputId": "431e9b83-a2bd-42de-e88e-1b5f3276a5de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "candidates_hist"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('исследование', 'движений'): ('S', 'S'),\n",
              " ('недоверие', 'власти'): ('S', 'S'),\n",
              " ('ограничивается', 'маккензи'): ('V', 'S'),\n",
              " ('ограничивается', 'перечисляет'): ('V', 'V'),\n",
              " ('ограничивается', 'рамками'): ('V', 'S'),\n",
              " ('перечисляет', 'причины'): ('V', 'S'),\n",
              " ('посвящает', 'книгу'): ('V', 'S'),\n",
              " ('посвящает', 'частью'): ('V', 'S'),\n",
              " ('рамками', 'исследования'): ('S', 'S'),\n",
              " ('рассматривать', 'год'): ('V', 'S'),\n",
              " ('частью', 'исследование'): ('S', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x54PidiaTS6",
        "colab_type": "code",
        "outputId": "bd9998c4-e452-419d-ab7e-089d086f2420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "candidates_ling = search(bad_text_ling, pd.read_csv('suggestions_ling.csv'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 236 ms, sys: 7.97 ms, total: 244 ms\n",
            "Wall time: 249 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZr5EHPKfxkz",
        "colab_type": "code",
        "outputId": "722367a7-8503-4927-c483-0583e2330bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "candidates_ling"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('вопросы', 'наводящие'): ('S', 'V'),\n",
              " ('грамматики', 'языка'): ('S', 'S'),\n",
              " ('избегать', 'вопросы'): ('V', 'S'),\n",
              " ('изучение', 'опыта'): ('S', 'S'),\n",
              " ('опыта', 'ученых'): ('S', 'S'),\n",
              " ('предлагая', 'гипотезу'): ('V', 'S'),\n",
              " ('следует', 'избегать'): ('V', 'V'),\n",
              " ('создании', 'алфавита'): ('S', 'S'),\n",
              " ('соотносится', 'термин'): ('V', 'S'),\n",
              " ('соотносится', 'части'): ('V', 'S'),\n",
              " ('ссылаться', 'результаты'): ('V', 'S'),\n",
              " ('термин', 'истории'): ('S', 'S'),\n",
              " ('термин', 'морфология'): ('S', 'S'),\n",
              " ('точек', 'создании'): ('S', 'S'),\n",
              " ('употреблялся', 'значении'): ('V', 'S'),\n",
              " ('употреблялся', 'термин'): ('V', 'S'),\n",
              " ('части', 'грамматики'): ('S', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx3O9CrKcruQ",
        "colab_type": "text"
      },
      "source": [
        "Уже лучше! Все предложенные пары слов являются словосочетаниями (хотя функция *search()* всё ещё иногда ошибочно отлавливает правильные коллокации)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNRQxoRDnArZ",
        "colab_type": "text"
      },
      "source": [
        "#Поиск и ранжирование возможных замен\n",
        "Кандидаты на замену (не больше 10) подбираются по эталонному списку с учётом тэгов. Вес кандидата определяется по следующим метрикам: <br>\n",
        "\n",
        "**Если кандидат на замену есть в эталонном списке:**\n",
        "* **PMI (pointwise mutual information)**  – мера ассоциации между двумя словами, считается (по Manning and Schutze, 1999) как $\\log\\frac{P(x, y)}{P(x)P(y)}$, где $P(x)$ и $P(y)$ – вероятность появления в корпусе слов $x$ и $y$ соответственно, а $P(x, y)$ – вероятность появления их биграммы. Часто используется как метрика устойчивости словосочетаний. Может быть как положительной, так и отрицательной (но в наших эталонных списках PMI всегда положительный). Чем больше абсолютное значение PMI двух слов, тем больше они зависимы. PMI абсолютно независимых слов равна 0.<br>\n",
        "* **Косинусная близость** (посчитанная с помощью word2vec) между правильным словом и словом на замену.\n",
        "\n",
        "**Если в эталонном списке есть только оба слова кандидата по отдельности:**\n",
        "* Близость слов в коллокационном кластере. Допустим, есть пара слов $N$ и $V$, у которых в эталонном списке есть следующие коллокаты: $N(V_{11}, V_{12}, V_{13})$, $V(N_{11}, N_{12}, N_{13})$. У данных коллокатов есть свои пары $V_{11}(N_{21}, N_{22})$, $V_{12}(N_{23}, N_{24})$ и т.д. Мера близости $N$ и $V$ по кластеру - это количество таких слов $N_{21}, N_{22} \\ldots $, которые совпадают с коллокатами $V(N_{11}, N_{12}, N_{13})$, и таких слов $V_{21}, V_{22} \\ldots $, которые совпадают с коллокатами $N(V_{11}, V_{12}, V_{13})$. Точно также она может считаться для пар $N$ и $N$ или $V$ и $V$.\n",
        "\n",
        "\n",
        "Подробнее об этом алгоритме: https://aclweb.org/anthology/W09-2107 <br>\n",
        "Проблема: функция *search()* всё ещё часто ошибочно находит правильные коллокации, которые не нужно заменять (например, \"посвящает книгу\", \"термин морфология\"). Решение: ввести дополнительный критерий отсева.  Например, считать PMI для \"неправильного\" словосочетания, и если он больше, чем у лучшего из кандидатов на замену, не заменять эту коллокацию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5sILrLZNH25",
        "colab_type": "text"
      },
      "source": [
        "При подсчёте PMI использовались предварительно подсчитанные вероятности вхождений всех униграмм и биграмм в корпус. <br>\n",
        "Код, подсчитывающий вероятности: https://github.com/vyhuholl/cat_collocations/blob/master/uni_and_bigram_probability_counts.ipynb<br>\n",
        "Результаты: <br>\n",
        "https://www.dropbox.com/s/gxbmp952qwl03db/unigrams.pkl?dl=0 – для униграмм  <br>\n",
        " https://www.dropbox.com/s/o0f678z59mlu1d1/bigrams.pkl?dl=0 – для биграмм<br>\n",
        "Частотные списки, использованные при подсчёте вероятностей: https://drive.google.com/drive/folders/1k_N-DZ-nLL5ro66-LxIaE4-dRwirdwZh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIHTVArTdBkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.dropbox.com/s/gxbmp952qwl03db/unigrams.pkl?dl=0 -O unigrams.pkl\n",
        "!wget https://www.dropbox.com/s/o0f678z59mlu1d1/bigrams.pkl?dl=0 -O bigrams.pkl\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvUmiPaZDl6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"unigrams.pkl\", \"rb\") as file:\n",
        "    unigrams = pickle.load(file)\n",
        "with open(\"bigrams.pkl\", \"rb\") as file:\n",
        "    bigrams = pickle.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc1MD9gqfJ8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "\n",
        "\n",
        "def PMI(word_1, word_2):\n",
        "    if word_1 in unigrams and word_2 in unigrams \\\n",
        "            and f\"{word_1} {word_2}\" in bigrams:\n",
        "        return log(bigrams[f\"{word_1} {word_2}\"] /\n",
        "                   (unigrams[word_1] * unigrams[word_2]), 2)\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NIxLK6negot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5fa3d1f1-0430-480e-d29f-6a3c5a251764"
      },
      "source": [
        "# посмотрим, правильно ли работает функция –\n",
        "# для нескольких эталонных словосочетаний\n",
        "# сравним PMI, посчитанное функцией\n",
        "# и PMI, указанное в эталонных списках\n",
        "print(PMI(\"реализацию\", \"носового\")) # значение в эталонном списке – 10.948051\n",
        "print(PMI(\"актором\", \"оформляет\")) # значение в эталонном списке – 17.482237\n",
        "print(PMI(\"адрес\", \"фон\")) # значение в эталонном списке – 7.276692\n",
        "print(PMI(\"хватает\", \"глубины\")) # значение в эталонном списке – 13.626561\n",
        "print(PMI(\"требованию\", \"истца\")) # значение в эталонном списке – 10.709151\n",
        "print(PMI(\"исследования\", \"ефимова\")) # значение в эталонном списке – 7.723045\n",
        "print(PMI(\"выбор\", \"работников\")) # значение в эталонном списке – 4.089518"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.622390362568218\n",
            "15.832522922888293\n",
            "10.251731553169732\n",
            "13.894368245176478\n",
            "12.1509383953229\n",
            "8.967164778531066\n",
            "7.120048201210611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yiz3xjxjMaW",
        "colab_type": "text"
      },
      "source": [
        "Значения PMI, посчитанные функцией, достаточно близки к тем, которые были посчитаны для эталонных списков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvGG9JO4w0H2",
        "colab_type": "text"
      },
      "source": [
        "Word2Vec модель из rusvectores работает только с леммами слов, к которым приклеены тэги. Поэтому нам понадобится pymorphy для лемматизации. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W387aVOyE5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pymorphy2\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZfN0Y5Nx2eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QqOHnrvz3jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(word, tag):\n",
        "    if tag=='S':\n",
        "        return morph.parse(word)[0].normal_form+'_'+'NOUN'\n",
        "    elif tag=='V':\n",
        "        return morph.parse(word)[0].normal_form+'_'+'VERB'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOKXYb76hvzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def suggest(candidates, collocations):\n",
        "    \"\"\"candidates – словарь, где ключи – пары слов,\n",
        "    а значения – пары тэгов, collocations –\n",
        "    датафрейм pandas. Возвращается\n",
        "    словарь corrections, где ключи –\n",
        "    плохие коллокации, а значения – списки\n",
        "    замен (пара \"замена + её вероятность),\n",
        "    упорядоченные от наиболее вероятной\n",
        "    до наименее.\"\"\"\n",
        "    max_value = max(collocations.pmi) + 1\n",
        "    corrections = dict()\n",
        "    for bigram in candidates:\n",
        "        max_pmi = 0\n",
        "        suggestions = dict()\n",
        "        word_1, word_2 = bigram[0], bigram[1]\n",
        "        tag_1, tag_2 = candidates[bigram][0], candidates[bigram][1]\n",
        "        # в words_1 и words_2 будут храниться те кандидаты\n",
        "        # на замену первого и второго слова соответственно\n",
        "        # которые встречаются в эталонном списке по отдельности,\n",
        "        # не образуя коллокации\n",
        "        words_1 = []\n",
        "        words_2 = []\n",
        "        for i in range(len(collocations) - 1):\n",
        "            # попробуем заменить первое слово, если второе совпадает\n",
        "            if collocations.first_tag[i] == tag_1 \\\n",
        "                    and collocations.second_word[i] == word_2:\n",
        "                weight = collocations.pmi[i]\n",
        "                if weight > max_pmi:\n",
        "                    max_pmi = weight\n",
        "                wv_1 = convert(collocations.first_word[i], tag_1)\n",
        "                wv_2 = convert(word_1, tag_1)\n",
        "                if wv_1 in model.wv and wv_2 in model.wv:\n",
        "                    weight += model.wv.similarity(wv_1, wv_2)\n",
        "                weight /= max_value\n",
        "                suggestions[(collocations.first_word[i], word_2)] = weight\n",
        "                # нормируем, чтобы все вероятности лежали в диапазоне от 0 до 1\n",
        "                words_1.append(collocations.first_word[i])\n",
        "            # теперь попробуем заменить второе слово, если первое совпадает\n",
        "            if collocations.first_word[i] == word_1 \\\n",
        "                    and collocations.second_tag[i] == tag_2:\n",
        "                weight = collocations.pmi[i]\n",
        "                if weight > max_pmi:\n",
        "                    max_pmi = weight\n",
        "                wv_1 = convert(collocations.second_word[i], tag_2)\n",
        "                wv_2 = convert(word_2, tag_2)\n",
        "                if wv_1 in model.wv and wv_2 in model.wv:\n",
        "                    weight += model.wv.similarity(wv_1, wv_2)\n",
        "                weight /= max_value\n",
        "                suggestions[(word_1, collocations.second_word[i])] = weight\n",
        "                words_2.append(collocations.second_word[i])\n",
        "        # если остались отдельные кандидаты\n",
        "        # как на замену word_1, так и на замену word_2\n",
        "        # то для них тоже считаем вероятности\n",
        "        if len(words_1) > 0 and len(words_2) > 0:\n",
        "            for word in words_1:\n",
        "                for i in range(len(collocations) - 1):\n",
        "                    first = collocations.first_word[i]\n",
        "                    second = collocations.second_word[i]\n",
        "                    if first == word and second in words_2:\n",
        "                        if (word, second) not in suggestions:\n",
        "                            suggestions[(word, second)] = 1.0 / len(words_2)\n",
        "                        else:\n",
        "                            suggestions[(word, second)] += 1.0 / len(words_2)\n",
        "            for word in words_2:\n",
        "                for i in range(len(collocations) - 1):\n",
        "                    first = collocations.first_word[i]\n",
        "                    second = collocations.second_word[i]\n",
        "                    if first in words_1 and second == word:\n",
        "                        if (first, word) not in suggestions:\n",
        "                            suggestions[(first, word)] = 1.0 / len(words_1)\n",
        "                        else:\n",
        "                            suggestions[(first, word)] += 1.0 / len(words_1)\n",
        "        best = [item for item in sorted(suggestions.items(),\n",
        "                                        key=lambda x: x[-1],\n",
        "                                        reverse=True)[:10]\n",
        "                if item[1] >= 0.5]\n",
        "        if max_pmi > PMI(word_1, word_2):\n",
        "            corrections[bigram] = best\n",
        "    return corrections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFvUtfEAjwSg",
        "colab_type": "text"
      },
      "source": [
        "Проверим!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSNwLVrwk19l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "55dcfdc1-5723-4641-b3fc-965f9e541c7f"
      },
      "source": [
        "candidates_pol"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('выросли', 'расходы'): ('V', 'S'),\n",
              " ('умолчал', 'время'): ('V', 'S'),\n",
              " ('умолчал', 'данные'): ('V', 'S'),\n",
              " ('умолчал', 'населения'): ('V', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-b0_jOKjuyp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bc09af39-36aa-435c-90ed-7a7f416664b2"
      },
      "source": [
        "%%time\n",
        "suggestions_pol = suggest(candidates_pol, pd.read_csv('suggestions_pol.csv'))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.68 s, sys: 4.73 ms, total: 5.69 s\n",
            "Wall time: 5.69 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqfLKY43kVj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ea9d3ea4-c32c-4952-e1cf-5a969c1bc2af"
      },
      "source": [
        "for bad in suggestions_pol:\n",
        "    print(f\"Bad: {bad}.\")\n",
        "    print(\"Suggestions:\")\n",
        "    print('\\n'.join(f\"{i[0]}, {i[1]}\" for i in suggestions_pol[bad]))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad: ('умолчал', 'время').\n",
            "Suggestions:\n",
            "('настало', 'время'), 0.5706590754770549\n",
            "('потребуется', 'время'), 0.5621175967293761\n",
            "\n",
            "\n",
            "Bad: ('умолчал', 'данные').\n",
            "Suggestions:\n",
            "('обобщая', 'данные'), 0.596687089644353\n",
            "\n",
            "\n",
            "Bad: ('выросли', 'расходы').\n",
            "Suggestions:\n",
            "('оптимизирует', 'расходы'), 0.7035836770729458\n",
            "('увеличили', 'расходы'), 0.6582008296985596\n",
            "('требуются', 'расходы'), 0.6052636331236313\n",
            "('свидетельствовать', 'расходы'), 0.5905498243138871\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96L-LIhvk7bO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "05be7947-f7e7-4195-dfa8-84ceccccc7bb"
      },
      "source": [
        "candidates_hist"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('исследование', 'движений'): ('S', 'S'),\n",
              " ('недоверие', 'власти'): ('S', 'S'),\n",
              " ('ограничивается', 'маккензи'): ('V', 'S'),\n",
              " ('ограничивается', 'перечисляет'): ('V', 'V'),\n",
              " ('ограничивается', 'рамками'): ('V', 'S'),\n",
              " ('перечисляет', 'причины'): ('V', 'S'),\n",
              " ('посвящает', 'книгу'): ('V', 'S'),\n",
              " ('посвящает', 'частью'): ('V', 'S'),\n",
              " ('рамками', 'исследования'): ('S', 'S'),\n",
              " ('рассматривать', 'год'): ('V', 'S'),\n",
              " ('частью', 'исследование'): ('S', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaKkRK_JlAZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "97de3feb-95a3-4048-da98-48ba7aabd32e"
      },
      "source": [
        "%%time\n",
        "suggestions_hist = suggest(candidates_hist, pd.read_csv('suggestions_hist.csv'))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.68 s, sys: 6.96 ms, total: 8.69 s\n",
            "Wall time: 8.69 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxL8mgZwlHjL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d5b7eb4-409c-4fbf-83f4-4edbb1e99442"
      },
      "source": [
        "for bad in suggestions_hist:\n",
        "    print(f\"Bad: {bad}.\")\n",
        "    print(\"Suggestions:\")\n",
        "    print('\\n'.join(f\"{i[0]}, {i[1]}\" for i in suggestions_hist[bad]))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad: ('ограничивается', 'маккензи').\n",
            "Suggestions:\n",
            "('ограничивается', 'проведением'), 0.9506715008756121\n",
            "\n",
            "\n",
            "Bad: ('ограничивается', 'рамками').\n",
            "Suggestions:\n",
            "('ограничивается', 'проведением'), 0.9639394046257748\n",
            "\n",
            "\n",
            "Bad: ('рамками', 'исследования').\n",
            "Suggestions:\n",
            "('ракурса', 'исследования'), 0.7055136153085221\n",
            "('объекта', 'исследования'), 0.705067710521165\n",
            "('объектами', 'исследования'), 0.705067710521165\n",
            "('достоинством', 'исследования'), 0.7005627433862813\n",
            "('структура', 'исследования'), 0.621163092281545\n",
            "('фонда', 'исследования'), 0.6176795702425913\n",
            "('метода', 'исследования'), 0.6157198208569395\n",
            "('теме', 'исследования'), 0.5319833779033427\n",
            "\n",
            "\n",
            "Bad: ('перечисляет', 'причины').\n",
            "Suggestions:\n",
            "('объяснить', 'причины'), 0.6861508304288867\n",
            "('рассматривает', 'причины'), 0.6591480444472243\n",
            "('рассматриваются', 'причины'), 0.6309382150289891\n",
            "\n",
            "\n",
            "Bad: ('рассматривать', 'год').\n",
            "Suggestions:\n",
            "('рассматривать', 'круги'), 0.6918590182218118\n",
            "('рассматривать', 'власть'), 0.6191679544646704\n",
            "\n",
            "\n",
            "Bad: ('посвящает', 'книгу').\n",
            "Suggestions:\n",
            "('написать', 'книгу'), 0.6468128587460382\n",
            "\n",
            "\n",
            "Bad: ('посвящает', 'частью').\n",
            "Suggestions:\n",
            "('являясь', 'частью'), 0.7326014591465178\n",
            "('опираясь', 'частью'), 0.6550543064367444\n",
            "\n",
            "\n",
            "Bad: ('частью', 'исследование').\n",
            "Suggestions:\n",
            "('частью', 'ландшафта'), 0.785929290468445\n",
            "('частью', 'обонежской'), 0.7731686123921617\n",
            "('фактам', 'исследование'), 0.7224445731508572\n",
            "('частью', 'природы'), 0.5429967720788104\n",
            "\n",
            "\n",
            "Bad: ('исследование', 'движений').\n",
            "Suggestions:\n",
            "('исследование', 'отто'), 0.7100111693644945\n",
            "('исследование', 'битва'), 0.6399378943205835\n",
            "\n",
            "\n",
            "Bad: ('недоверие', 'власти').\n",
            "Suggestions:\n",
            "('недоверие', 'савинкову'), 0.8534123422617957\n",
            "('репрезентация', 'власти'), 0.6326532757119975\n",
            "('формы', 'власти'), 0.6247062154016259\n",
            "('эшелонах', 'власти'), 0.618829301381188\n",
            "('концентрация', 'власти'), 0.5706596762154488\n",
            "('орган', 'власти'), 0.5704643768645913\n",
            "('органа', 'власти'), 0.5704643768645913\n",
            "('элементом', 'власти'), 0.5667025173376232\n",
            "('центром', 'власти'), 0.5301736939194329\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7va1Z4nulNTo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "290c3b59-93e7-4aa4-f21e-afb9800d86e0"
      },
      "source": [
        "candidates_ling"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('вопросы', 'наводящие'): ('S', 'V'),\n",
              " ('грамматики', 'языка'): ('S', 'S'),\n",
              " ('избегать', 'вопросы'): ('V', 'S'),\n",
              " ('изучение', 'опыта'): ('S', 'S'),\n",
              " ('опыта', 'ученых'): ('S', 'S'),\n",
              " ('предлагая', 'гипотезу'): ('V', 'S'),\n",
              " ('следует', 'избегать'): ('V', 'V'),\n",
              " ('создании', 'алфавита'): ('S', 'S'),\n",
              " ('соотносится', 'термин'): ('V', 'S'),\n",
              " ('соотносится', 'части'): ('V', 'S'),\n",
              " ('ссылаться', 'результаты'): ('V', 'S'),\n",
              " ('термин', 'истории'): ('S', 'S'),\n",
              " ('термин', 'морфология'): ('S', 'S'),\n",
              " ('точек', 'создании'): ('S', 'S'),\n",
              " ('употреблялся', 'значении'): ('V', 'S'),\n",
              " ('употреблялся', 'термин'): ('V', 'S'),\n",
              " ('части', 'грамматики'): ('S', 'S')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRfPG6x4lU8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "16d2bece-d78c-4e3b-d2ec-cb01dccec76a"
      },
      "source": [
        "%%time\n",
        "suggestions_ling = suggest(candidates_ling, pd.read_csv('suggestions_ling.csv'))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 22s, sys: 20.8 ms, total: 1min 22s\n",
            "Wall time: 1min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXZx2h2Plcnz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a724b34a-4533-4160-90aa-383f5bc1f114"
      },
      "source": [
        "for bad in suggestions_ling:\n",
        "    print(f\"Bad: {bad}.\")\n",
        "    print(\"Suggestions:\")\n",
        "    print('\\n'.join(f\"{i[0]}, {i[1]}\" for i in suggestions_ling[bad]))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad: ('следует', 'избегать').\n",
            "Suggestions:\n",
            "('стремился', 'избегать'), 0.8212504884404777\n",
            "('следует', 'уделять'), 0.6218461564194934\n",
            "('следует', 'простить'), 0.6193272360438431\n",
            "('следует', 'вознести'), 0.6170769625499726\n",
            "('следует', 'применять'), 0.5716005921887101\n",
            "('следует', 'определять'), 0.5702201276884263\n",
            "('следует', 'увязать'), 0.5697844014774479\n",
            "('следует', 'напомнить'), 0.5655767932970802\n",
            "('следует', 'упомянуть'), 0.5654509246206123\n",
            "('следует', 'отметить'), 0.5605653249470472\n",
            "\n",
            "\n",
            "Bad: ('избегать', 'вопросы').\n",
            "Suggestions:\n",
            "('избегать', 'пересказа'), 0.8148288932660556\n",
            "('избегать', 'запретов'), 0.770124670554275\n",
            "('обсуждались', 'вопросы'), 0.5251686057974542\n",
            "\n",
            "\n",
            "Bad: ('точек', 'создании').\n",
            "Suggestions:\n",
            "('точек', 'зрения'), 0.6324493110413522\n",
            "\n",
            "\n",
            "Bad: ('создании', 'алфавита').\n",
            "Suggestions:\n",
            "('создании', 'ритма'), 0.6001357603246426\n",
            "('создании', 'мия'), 0.5238329906833026\n",
            "('создании', 'памятника'), 0.5218224846940478\n",
            "\n",
            "\n",
            "Bad: ('предлагая', 'гипотезу').\n",
            "Suggestions:\n",
            "('проверим', 'гипотезу'), 0.7264362527255138\n",
            "('проверить', 'гипотезу'), 0.6235550857722846\n",
            "('поддержать', 'гипотезу'), 0.6104112517136872\n",
            "('подтверждают', 'гипотезу'), 0.6005507058119104\n",
            "\n",
            "\n",
            "Bad: ('ссылаться', 'результаты').\n",
            "Suggestions:\n",
            "\n",
            "\n",
            "\n",
            "Bad: ('изучение', 'опыта').\n",
            "Suggestions:\n",
            "('изучение', 'хронологии'), 0.6835029161944028\n",
            "('изучение', 'варьирования'), 0.6551846532549404\n",
            "('изучение', 'полисемии'), 0.6493330389306091\n",
            "('изучение', 'латыни'), 0.6159620951985773\n",
            "('изучение', 'перфекта'), 0.5830834608327922\n",
            "('изучение', 'соотношения'), 0.5182263307702428\n",
            "\n",
            "\n",
            "Bad: ('опыта', 'ученых').\n",
            "Suggestions:\n",
            "('имена', 'ученых'), 0.5348902580311128\n",
            "\n",
            "\n",
            "Bad: ('соотносится', 'термин').\n",
            "Suggestions:\n",
            "('используем', 'термин'), 0.6255430236228778\n",
            "('применим', 'термин'), 0.6012138120536881\n",
            "('появился', 'термин'), 0.5313922358453056\n",
            "\n",
            "\n",
            "Bad: ('термин', 'морфология').\n",
            "Suggestions:\n",
            "('термин', 'инхоатив'), 0.6597354660902077\n",
            "('термин', 'односубъектность'), 0.6597354660902077\n",
            "('термин', 'стобалльник'), 0.6597354660902077\n",
            "('термин', 'интерлингвистика'), 0.6348623616766185\n",
            "('термин', 'пазилогия'), 0.6082948826135931\n",
            "('термин', 'политологии'), 0.6077979442626577\n",
            "('термин', 'контрагент'), 0.5474746956009472\n",
            "('термин', 'орфофония'), 0.5402941300984557\n",
            "\n",
            "\n",
            "Bad: ('части', 'грамматики').\n",
            "Suggestions:\n",
            "('упрощение', 'грамматики'), 0.6984624577459776\n",
            "('упрощением', 'грамматики'), 0.6984624577459776\n",
            "('идеологии', 'грамматики'), 0.6948191679143427\n",
            "('сторонам', 'грамматики'), 0.6209168494295955\n",
            "('упрощении', 'грамматики'), 0.6169310619203299\n",
            "('правилам', 'грамматики'), 0.5796983782788843\n",
            "('механизмов', 'грамматики'), 0.5745415062489982\n",
            "('проблемам', 'грамматики'), 0.5630279995611461\n",
            "('вопросам', 'грамматики'), 0.5604378322731209\n",
            "('части', 'квятковский'), 0.5476101164989539\n",
            "\n",
            "\n",
            "Bad: ('грамматики', 'языка').\n",
            "Suggestions:\n",
            "('грамматики', 'щерба'), 0.6996030476253469\n",
            "('грамматики', 'варшава'), 0.6888652653190486\n",
            "('грамматики', 'русграм'), 0.6847061053150446\n",
            "('грамматики', 'пор'), 0.6434247897636205\n",
            "('грамматики', 'зависимостей'), 0.6099259983174329\n",
            "('архаизации', 'языка'), 0.5254397601677886\n",
            "('теоретиков', 'языка'), 0.5196092381106747\n",
            "('освоение', 'языка'), 0.5159324097692919\n",
            "('прозодия', 'языка'), 0.5052246376608074\n",
            "\n",
            "\n",
            "Bad: ('употреблялся', 'термин').\n",
            "Suggestions:\n",
            "('используем', 'термин'), 0.6413827986427618\n",
            "('применим', 'термин'), 0.5983196396451472\n",
            "('появился', 'термин'), 0.5348024018366483\n",
            "\n",
            "\n",
            "Bad: ('термин', 'истории').\n",
            "Suggestions:\n",
            "('термин', 'инхоатив'), 0.6597354660902077\n",
            "('термин', 'односубъектность'), 0.6597354660902077\n",
            "('термин', 'стобалльник'), 0.6597354660902077\n",
            "('очерк', 'истории'), 0.644919903837851\n",
            "('термин', 'интерлингвистика'), 0.6266307263829308\n",
            "('термин', 'пазилогия'), 0.6082948826135931\n",
            "('термин', 'политологии'), 0.6082235600164533\n",
            "('аудиозапись', 'истории'), 0.5869164160255654\n",
            "('термин', 'контрагент'), 0.549477261360791\n",
            "('термин', 'орфофония'), 0.5402941300984557\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-SOR4f8jaQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}